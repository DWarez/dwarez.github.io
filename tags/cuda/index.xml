<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cuda on The ML Surgeon</title><link>https://dwarez.github.io/tags/cuda/</link><description>Recent content in Cuda on The ML Surgeon</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 Dario Salvati</copyright><lastBuildDate>Mon, 21 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://dwarez.github.io/tags/cuda/index.xml" rel="self" type="application/rss+xml"/><item><title>The Operating Room Setup</title><link>https://dwarez.github.io/posts/dev-setup/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/dev-setup/</guid><description>&lt;p>Undoubtedly, one of the most critical aspects of machine learning is understanding the theory—without grasping how machines learn, you&amp;rsquo;ll never excel as an ML Surgeon! But being a surgeon isn&amp;rsquo;t just about theory; it’s about getting your hands dirty—writing code, setting up infrastructures, and operating on the intricacies of data. That’s why having a tailored, efficient, and &lt;strong>functional&lt;/strong> development setup is essential to stay productive and ensure everything gets done right.&lt;/p></description></item><item><title>Performing Kernel Surgery: Profiling CUDA Kernels with NVIDIA Nsight Compute</title><link>https://dwarez.github.io/posts/profiling-introduction/</link><pubDate>Mon, 15 Jul 2024 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/profiling-introduction/</guid><description>&lt;p>Being a Machine Learning Surgeon is not an easy life. We not only have to deal with intricate machine learning systems but also navigate the additional complexities surrounding them. To be a proficient ML Surgeon, we must develop a diverse skill set. First and foremost, we need a deep understanding of machine learning and deep learning. Additionally, we must be adept at writing software, building infrastructures to host and integrate models, managing large volumes of data, and much more. This requires familiarity with numerous tools.&lt;/p></description></item><item><title>A Machine Learning Surgeon’s Toolkit: Advanced Matrix Multiplication in CUDA</title><link>https://dwarez.github.io/posts/matrix-multiplication/</link><pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/matrix-multiplication/</guid><description>&lt;p>During the first year of my Master&amp;rsquo;s Degree in Computer Science, I had to complete a project for a Machine Learning course. It involved implementing a small feed-forward neural network framework from scratch, using only numerical libraries and coding elements such as loss functions, backpropagation, and the feed-forward step.&lt;/p></description></item><item><title>Hello CUDA: A Surgical Dissection</title><link>https://dwarez.github.io/posts/hello-cuda/</link><pubDate>Mon, 06 May 2024 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/hello-cuda/</guid><description>&lt;p>In case you didn&amp;rsquo;t already know, &lt;a href="https://it.wikipedia.org/wiki/CUDA" target="_blank">CUDA&lt;/a> is a parallel computing platform and API, developed by NVIDIA, that enables programmers to exploit certain types of GPUs. Not too long ago (around until 2007), GPUs were solely utilized for graphics rendering, and programmers had to depend on very specific graphics APIs to utilize them for solving general problems.&lt;/p></description></item></channel></rss>