<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Triton on The ML Surgeon</title><link>https://dwarez.github.io/tags/triton/</link><description>Recent content in Triton on The ML Surgeon</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Dario Salvati</copyright><lastBuildDate>Sat, 14 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://dwarez.github.io/tags/triton/index.xml" rel="self" type="application/rss+xml"/><item><title>From Sequential to Parallel: Your Journey into GPU Programming with Triton</title><link>https://dwarez.github.io/posts/intro-triton/</link><pubDate>Sat, 14 Jun 2025 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/intro-triton/</guid><description>&lt;p>We all know that GPU programming is hard. There are many layers of complexity that make writing a kernel difficult: thinking in a parallel way (which goes against our natural sequential thinking), understanding the math behind a certain operation, keeping track of data movement, memory hierarchies, occupancy, concurrency, boundaries, and much more.
Adding to that complexity, the languages used to write kernels aren&amp;rsquo;t straightforward for all developers, especially if you come from an AI/ML background and aren&amp;rsquo;t familiar with low-level programming.&lt;/p></description></item></channel></rss>