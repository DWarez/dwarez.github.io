<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gpu-Programming on The ML Surgeon</title><link>https://dwarez.github.io/tags/gpu-programming/</link><description>Recent content in Gpu-Programming on The ML Surgeon</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 Dario Salvati</copyright><lastBuildDate>Mon, 06 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://dwarez.github.io/tags/gpu-programming/index.xml" rel="self" type="application/rss+xml"/><item><title>Hello CUDA: A Surgical Dissection</title><link>https://dwarez.github.io/posts/hello-cuda/</link><pubDate>Mon, 06 May 2024 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/hello-cuda/</guid><description>&lt;p>In case you didn&amp;rsquo;t already know, &lt;a href="https://it.wikipedia.org/wiki/CUDA" target="_blank">CUDA&lt;/a> is a parallel computing platform and API, developed by NVIDIA, that enables programmers to exploit certain types of GPUs. Not too long ago (around until 2007), GPUs were solely utilized for graphics rendering, and programmers had to depend on very specific graphics APIs to utilize them for solving general problems.&lt;/p></description></item></channel></rss>