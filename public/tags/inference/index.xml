<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inference on The ML Surgeon</title>
    <link>http://localhost:1313/tags/inference/</link>
    <description>Recent content in Inference on The ML Surgeon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© 2024 Dario Salvati</copyright>
    <lastBuildDate>Sun, 10 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/inference/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Quantization</title>
      <link>http://localhost:1313/posts/quantization/</link>
      <pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/quantization/</guid>
      <description>&lt;p&gt;As humans, we perceive space and time as a seamless, continuous flow. This perception leads us to believe that continuity—and perhaps even infinity—is a fundamental aspect of nature. However, some scientific theories challenge this assumption. For example, &lt;strong&gt;string theory&lt;/strong&gt; posits that the universe&amp;rsquo;s fundamental components are tiny, vibrating strings, where different vibrations define different particles. Similarly, &lt;strong&gt;loop quantum gravity&lt;/strong&gt; suggests that space itself is made up of discrete &amp;ldquo;grains,&amp;rdquo; implying that reality might not be as continuous as it appears.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>An Introduction to Sparsity for Efficient Neural Network Inference</title>
      <link>http://localhost:1313/posts/pruning-intro/</link>
      <pubDate>Sun, 05 May 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/pruning-intro/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;NOTE:&lt;/em&gt;&lt;/strong&gt;  This post was written before the Machine Learning Surgeon got in charge of the blog, that&amp;rsquo;s why there are no references to surgical operations!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Large Language Model&lt;/strong&gt;. How many times did you read that term? Nowadays, the popularity of Artificial Intelligence is to be attributed to the exceptional results obtained, in the past few years, by applications that leverage large models. Surely, you know the most popular one, ChatGPT, made by OpenAI.&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
