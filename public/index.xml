<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The ML Surgeon</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on The ML Surgeon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© 2024 Dario Salvati</copyright>
    <lastBuildDate>Sun, 10 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Quantization</title>
      <link>http://localhost:1313/posts/quantization/</link>
      <pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/quantization/</guid>
      <description>As humans, we perceive the space and time around us as continuous. This continuity suggests that the concept of infinity is intrinsic to nature. However, some theories challenge this view, proposing that reality might, in fact, be discrete.</description>
      
    </item>
    
    <item>
      <title>The Operating Room Setup</title>
      <link>http://localhost:1313/posts/dev-setup/</link>
      <pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/dev-setup/</guid>
      <description>Undoubtedly, one of the most critical aspects of machine learning is understanding the theory—without grasping how machines learn, you&amp;rsquo;ll never excel as an ML Surgeon! But being a surgeon isn&amp;rsquo;t just about theory; it’s about getting your hands dirty—writing code, setting up infrastructures, and operating on the intricacies of data.</description>
      
    </item>
    
    <item>
      <title>Dissecting torch.compile: Surgical Precision in PyTorch Optimization</title>
      <link>http://localhost:1313/posts/torch-compile/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/torch-compile/</guid>
      <description>You can take a look at the GitHub repository of this blogpost at this link Remember when machine learning was done using Caffe? The ML Surgeon remembers that. If you didn’t catch the reference, too bad for you!</description>
      
    </item>
    
    <item>
      <title>A quick incision: ten minutes to RAG</title>
      <link>http://localhost:1313/posts/ten-minutes-to-rag/</link>
      <pubDate>Thu, 29 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/ten-minutes-to-rag/</guid>
      <description>Hello, fellow surgeons! How is life treating you? I hope you&amp;rsquo;ve spent your vacation relaxing, far, far away from the tools of our trade. After all, a good surgeon needs to rest after a long year of work and learning, right?</description>
      
    </item>
    
    <item>
      <title>Performing Kernel Surgery: Profiling CUDA Kernels with NVIDIA Nsight Compute</title>
      <link>http://localhost:1313/posts/profiling-introduction/</link>
      <pubDate>Mon, 15 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/profiling-introduction/</guid>
      <description>Being a Machine Learning Surgeon is not an easy life. We not only have to deal with intricate machine learning systems but also navigate the additional complexities surrounding them. To be a proficient ML Surgeon, we must develop a diverse skill set.</description>
      
    </item>
    
    <item>
      <title>A Machine Learning Surgeon’s Toolkit: Advanced Matrix Multiplication in CUDA</title>
      <link>http://localhost:1313/posts/matrix-multiplication/</link>
      <pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/matrix-multiplication/</guid>
      <description>During the first year of my Master&amp;rsquo;s Degree in Computer Science, I had to complete a project for a Machine Learning course. It involved implementing a small feed-forward neural network framework from scratch, using only numerical libraries and coding elements such as loss functions, backpropagation, and the feed-forward step.</description>
      
    </item>
    
    <item>
      <title>Cerebral Cortex and Hippocampus: Understanding the Computational and Memory Design of GPUs</title>
      <link>http://localhost:1313/posts/cpu-gpu-architecture/</link>
      <pubDate>Fri, 14 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/cpu-gpu-architecture/</guid>
      <description>Would you operate on a human body without knowing its organs? Similarly, how can you effectively write a GPU kernel without understanding the underlying hardware? This is why it&amp;rsquo;s crucial to understand how GPUs function.</description>
      
    </item>
    
    <item>
      <title>Hello CUDA: A Surgical Dissection</title>
      <link>http://localhost:1313/posts/hello-cuda/</link>
      <pubDate>Mon, 06 May 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/hello-cuda/</guid>
      <description>In case you didn&amp;rsquo;t already know, CUDA is a parallel computing platform and API, developed by NVIDIA, that enables programmers to exploit certain types of GPUs. Not too long ago (around until 2007), GPUs were solely utilized for graphics rendering, and programmers had to depend on very specific graphics APIs to utilize them for solving general problems.</description>
      
    </item>
    
    <item>
      <title>An Introduction to Sparsity for Efficient Neural Network Inference</title>
      <link>http://localhost:1313/posts/pruning-intro/</link>
      <pubDate>Sun, 05 May 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/pruning-intro/</guid>
      <description>NOTE: This post was written before the Machine Learning Surgeon got in charge of the blog, that&amp;rsquo;s why there are no references to surgical operations!
Large Language Model. How many times did you read that term?</description>
      
    </item>
    
  </channel>
</rss>
