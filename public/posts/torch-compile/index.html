<!DOCTYPE html>
<html lang="en" dir="ltr" class="scroll-smooth" data-default-appearance="dark"
  data-auto-appearance="true"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="en" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>Dissecting torch.compile: Surgical Precision in PyTorch Optimization &middot; The ML Surgeon</title>
  <meta name="title" content="Dissecting torch.compile: Surgical Precision in PyTorch Optimization &middot; The ML Surgeon" />
  
  <meta name="description" content="The low level side of machine learning." />
  <meta name="keywords" content="torch-compile, compiler, " />
  
  
  <link rel="canonical" href="http://localhost:1313/posts/torch-compile/" />
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/css/main.bundle.min.7e511937ade47127f0cc4d4943b7cc62b8f7cf37a9c19383694c5760ad479781345dbedf1b713a57a80254844a8966c81cb86298461c8f60c196036e053f9605.css"
    integrity="sha512-flEZN63kcSfwzE1JQ7fMYrj3zzepwZODaUxXYK1Hl4E0Xb7fG3E6V6gCVIRKiWbIHLhimEYcj2DBlgNuBT&#43;WBQ==" />
  
  
  <script type="text/javascript" src="/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js"
    integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj&#43;e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js"
    integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy="" data-copied=""></script>
  
  
  
  <script src="/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js" integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S&#43;Yti0U7QtuZvQ=="></script>
  
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/posts/torch-compile/">
  <meta property="og:site_name" content="The ML Surgeon">
  <meta property="og:title" content="Dissecting torch.compile: Surgical Precision in PyTorch Optimization">
  <meta property="og:description" content=" You can take a look at the GitHub repository of this blogpost at this link ">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-09-01T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-09-01T00:00:00+00:00">
    <meta property="article:tag" content="Torch-Compile">
    <meta property="article:tag" content="Compiler">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Dissecting torch.compile: Surgical Precision in PyTorch Optimization">
  <meta name="twitter:description" content=" You can take a look at the GitHub repository of this blogpost at this link ">

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "Dissecting torch.compile: Surgical Precision in PyTorch Optimization",
    "headline": "Dissecting torch.compile: Surgical Precision in PyTorch Optimization",
    
    "abstract": "\u003cblockquote\u003e\n\u003cp\u003eYou can take a look at the GitHub repository of this blogpost \u003ca href=\u0022https:\/\/github.com\/DWarez\/torch_compile_blogpost\u0022 target=\u0022_blank\u0022\u003e\u003cstrong\u003eat this link\u003c\/strong\u003e\u003c\/a\u003e   \n\n  \u003cspan class=\u0022relative inline-block align-text-bottom icon\u0022\u003e\n    \u003csvg xmlns=\u0022http:\/\/www.w3.org\/2000\/svg\u0022 viewBox=\u00220 0 496 512\u0022\u003e\u003cpath fill=\u0022currentColor\u0022 d=\u0022M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\u0022\/\u003e\u003c\/svg\u003e\n\n  \u003c\/span\u003e\n\n\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/posts\/torch-compile\/",
    "author" : {
      "@type": "Person",
      "name": "Dario Salvati"
    },
    "copyrightYear": "2024",
    "dateCreated": "2024-09-01T00:00:00\u002b00:00",
    "datePublished": "2024-09-01T00:00:00\u002b00:00",
    
    "dateModified": "2024-09-01T00:00:00\u002b00:00",
    
    "keywords": ["torch-compile","compiler"],
    
    "mainEntityOfPage": "true",
    "wordCount": "4776"
  }]
  </script>


  
  
  <meta name="author" content="Dario Salvati" />
  
  
  
  <link href="https://linkedin.com/in/dwarez" rel="me" />
  
  
  <link href="https://github.com/dwarez" rel="me" />
  
  
  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>











<link type="text/css" rel="stylesheet" href="/lib/katex/katex.min.68e17230ccd917b97b7a2def38a8108918599d8aa4f580bfb8cce5e13d23e4de43dcaba5f9000553cb2c10d0d1300aabfe5c433a3305ebd752609f0762a63e59.css" integrity="sha512-aOFyMMzZF7l7ei3vOKgQiRhZnYqk9YC/uMzl4T0j5N5D3Kul&#43;QAFU8ssENDRMAqr/lxDOjMF69dSYJ8HYqY&#43;WQ==" />


<script defer src="/lib/katex/katex.min.50f14e69d6a8da7128ae3b63974c544ed377c36d096b5e3750f114e84c89d668b9301d9b0ed3248969aa183aa2e3bc4d2c1e73d5dcb7d462890c45a18d424589.js" integrity="sha512-UPFOadao2nEorjtjl0xUTtN3w20Ja143UPEU6EyJ1mi5MB2bDtMkiWmqGDqi47xNLB5z1dy31GKJDEWhjUJFiQ=="></script>


<script defer src="/lib/katex/auto-render.min.6095714e3aadb63b14ddc4af69346ab12974c1b460654345f8d1860a0b68fcc51b22f68b757433193090bb80afc8965b65cb607e5541d0f5f0f4b2e64d69b9ff.js" integrity="sha512-YJVxTjqttjsU3cSvaTRqsSl0wbRgZUNF&#43;NGGCgto/MUbIvaLdXQzGTCQu4CvyJZbZctgflVB0PXw9LLmTWm5/w=="
  onload="renderMathInElement(document.body);"></script>








































































































































  
  

<script async src="https://www.googletagmanager.com/gtag/js?id=G-PEDMYR1V0K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PEDMYR1V0K');
</script>



  
  
  <meta name="theme-color"/>
  
  
</head>
<body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a>
  </div>
  
  
  <div class="min-h-[148px]"></div>
<div class="fixed inset-x-0 pl-[24px] pr-[24px]" style="z-index:100">
  <div id="menu-blur" class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div>
  <div class="relative max-w-[64rem] ml-auto mr-auto">
    <div style="padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px"
    class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3">
    
    
    
    <div>
        <a href="/" class="flex">
            <span class="sr-only">The ML Surgeon</span>

            
            <img src="/img/logo.png" width="250" height="250"
                class="logo max-h-[5rem] max-w-[5rem] object-scale-down object-left nozoom" alt="The ML Surgeon" />
            

        </a>
    </div>
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            
            <a href="/" class="text-base font-medium text-gray-500 hover:text-gray-900">The ML Surgeon</a>
            

        </nav>
        <nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12">

            
            
            
  <a href="/posts/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        Blog
    </p>
</a>



            
            
  <a href="https://linkedin.com/in/dwarez"  target="_blank"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <span >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>


    </span>
    
    <p class="text-base font-medium" title="">
        
    </p>
</a>



            
            
  <a href="https://github.com/dwarez"  target="_blank"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <span >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>


    </span>
    
    <p class="text-base font-medium" title="">
        
    </p>
</a>



            
            

            


            
            <button id="search-button" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            


            
            
            <div
                class="ltr:mr-14 rtl:ml-14 flex items-center">
                <button id="appearance-switcher" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400">
                    <div class="flex items-center justify-center dark:hidden">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                    </div>
                    <div class="items-center justify-center hidden dark:flex">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                    </div>
                </button>
            </div>
            

        </nav>
        <div class="flex md:hidden items-center space-x-5 md:ml-12 h-12">

            <span></span>

            


            
            <button id="search-button-mobile" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            
            <button id="appearance-switcher-mobile" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400" style="margin-right:5px">
                <div class="flex items-center justify-center dark:hidden">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                </div>
                <div class="items-center justify-center hidden dark:flex">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                </div>
            </button>
            

        </div>
    </div>
    <div class="-my-2 -mr-2 md:hidden">

        <label id="menu-button" class="block">
            
            <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
                

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>

  </span>


            </div>
            <div id="menu-wrapper" style="padding-top:5px;"
                class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50">
                <ul
                    class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl">

                    <li id="menu-close-button">
                        <span
                            class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>

</span>
                    </li>

                    

                    
  <li class="mt-1">
    <a href="/posts/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Blog
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="https://linkedin.com/in/dwarez"  target="_blank"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <div >
            

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>


        </div>
        
        <p class="text-bg font-bg" title="">
            
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="https://github.com/dwarez"  target="_blank"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <div >
            

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>


        </div>
        
        <p class="text-bg font-bg" title="">
            
        </p>
    </a>
</li>




                    

                </ul>
                
                

            </div>
        </label>
    </div>
</div>




<script>
    (function () {
        var $mainmenu = $('.main-menu');
        var path = window.location.pathname;
        $mainmenu.find('a[href="' + path + '"]').each(function (i, e) {
            $(e).children('p').addClass('active');
        });
    })();
</script>


  </div>
</div>
<script>
  window.addEventListener('scroll', function (e) {
    var scroll = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;
    var background_blur = document.getElementById('menu-blur');
    background_blur.style.opacity = (scroll / 300);
  });
</script>

  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      


<article>
  
  
  
  
  
  
 
  
   
  
 



<div id="hero" class="h-[150px] md:h-[200px]"></div>



    
    <div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom"
    style="background-image:url(/img/gpu_power_hu18357939832410660288.jpg);">
    


    <div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal">
    </div>
    <div
        class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal">
    </div>
</div>

<div id="background-blur" class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div>
<script>
    window.addEventListener('scroll', function (e) {
        var scroll = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;
        var background_blur = document.getElementById('background-blur');
        background_blur.style.opacity = (scroll / 300)
    });
</script>

  
  

  <header id="single_header" class="mt-5 max-w-prose">
    
    <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="inline hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/"
      >The ML Surgeon</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline ">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/posts/"
      >Posts</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/posts/torch-compile/"
      >Dissecting torch.compile: Surgical Precision in PyTorch Optimization</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


    
    <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
      Dissecting torch.compile: Surgical Precision in PyTorch Optimization
    </h1>
    <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
      





  
  













  









  



  



<div class="flex flex-row flex-wrap items-center">
  
  
  <span title="Reading time">23 mins</span><span class="px-2 text-primary-500">&middot;</span>


  
  

<span class="mb-[2px]">
  <a
    href="https://github.com/DWarez/dwarez.github.io/tree/master/content/posts/torch_compile/index.md"
    class="text-lg hover:text-primary-500"
    rel="noopener noreferrer"
    target="_blank"
    title="Edit content"
    ><span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 512 512"><path fill="currentColor" d="M441 58.9L453.1 71c9.4 9.4 9.4 24.6 0 33.9L424 134.1 377.9 88 407 58.9c9.4-9.4 24.6-9.4 33.9 0zM209.8 256.2L344 121.9 390.1 168 255.8 302.2c-2.9 2.9-6.5 5-10.4 6.1l-58.5 16.7 16.7-58.5c1.1-3.9 3.2-7.5 6.1-10.4zM373.1 25L175.8 222.2c-8.7 8.7-15 19.4-18.3 31.1l-28.6 100c-2.4 8.4-.1 17.4 6.1 23.6s15.2 8.5 23.6 6.1l100-28.6c11.8-3.4 22.5-9.7 31.1-18.3L487 138.9c28.1-28.1 28.1-73.7 0-101.8L474.9 25C446.8-3.1 401.2-3.1 373.1 25zM88 64C39.4 64 0 103.4 0 152V424c0 48.6 39.4 88 88 88H360c48.6 0 88-39.4 88-88V312c0-13.3-10.7-24-24-24s-24 10.7-24 24V424c0 22.1-17.9 40-40 40H88c-22.1 0-40-17.9-40-40V152c0-22.1 17.9-40 40-40H200c13.3 0 24-10.7 24-24s-10.7-24-24-24H88z"/></svg>
  </span>

</span></a
  >
</span><span class="px-2 text-primary-500">&middot;</span>


<script type="text/javascript" src="/js/zen-mode.min.63c8a202661f4a2063fdc2706685d668e8ea3da613da2224e9da527e5876e4f53dcac39ab60732626fb4151feae5d430d0cf44731e5d3c726522fcc1519c1547.js" integrity="sha512-Y8iiAmYfSiBj/cJwZoXWaOjqPaYT2iIk6dpSflh25PU9ysOatgcyYm&#43;0FR/q5dQw0M9Ecx5dPHJlIvzBUZwVRw=="></script>

<span class="mb-[2px]">
    <span id="zen-mode-button"
          class="text-lg hover:text-primary-500"
          title="Enable zen mode"
          data-title-i18n-disable="Enable zen mode"
          data-title-i18n-enable="Disable zen mode">
        <span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="50px" height="50px">
    <path fill="currentColor" d="M 12.980469 4 C 9.1204688 4 5.9804688 7.14 5.9804688 11 L 6 26 L 9.9804688 26 L 9.9804688 11 C 9.9804688 9.35 11.320469 8 12.980469 8 L 40.019531 8 C 41.679531 8 43.019531 9.35 43.019531 11 L 43.019531 39 C 43.019531 40.65 41.679531 42 40.019531 42 L 29 42 C 29 43.54 28.420938 44.94 27.460938 46 L 40.019531 46 C 43.879531 46 47.019531 42.86 47.019531 39 L 47.019531 11 C 47.019531 7.14 43.879531 4 40.019531 4 L 12.980469 4 z M 7 28 C 4.794 28 3 29.794 3 32 L 3 42 C 3 44.206 4.794 46 7 46 L 23 46 C 25.206 46 27 44.206 27 42 L 27 32 C 27 29.794 25.206 28 23 28 L 7 28 z M 7 32 L 23 32 L 23.001953 42 L 7 42 L 7 32 z"/>
</svg>
  </span>

</span>
    </span>
</span>
  

  
  
</div>


<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
</div>




<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/torch-compile/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Torch-Compile
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/compiler/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Compiler
  </span>
</span>
  </span>
  
  
  
  
</div>




    </div>

    
    
    
    
    

    

    
      
      
        
        
<div class="flex author">
  
    
    
      
    
    
      
        
      
      <img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width="96" height="96"
      alt="Dario Salvati" src="/img/avatar_hu9627619460781864252.jpg" />
    
  
  <div class="place-self-center">
    
    <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
      Author
    </div>
    <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
      Dario Salvati
    </div>
    
    
    <div class="text-sm text-neutral-700 dark:text-neutral-400">A surgeon for Machine Learning models.</div>
    
    <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://linkedin.com/in/dwarez"
          target="_blank"
          aria-label="Linkedin"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>

</span></a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://github.com/dwarez"
          target="_blank"
          aria-label="Github"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>

</span></a
        >
      
    
  </div>

</div>
  </div>
</div>

      

      

      
      <div class="mb-5"></div>
      

    

  </header>
  
  <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
    
     <div
      class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8">
      <div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]">

         <details open id="TOCView"
  class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block">
  <summary
    class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#dissecting-torchcompile-a-surgeons-approach-to-pytorch-optimization">Dissecting torch.compile: A Surgeon’s Approach to PyTorch Optimization</a></li>
    <li><a href="#things-to-know-before-cutting-deep">Things to know before cutting deep</a>
      <ul>
        <li><a href="#slicing-through-the-layers-dissecting-pytorchs-computational-graphs">Slicing Through the Layers: Dissecting PyTorch’s Computational Graphs</a></li>
        <li><a href="#probing-the-depths-surgical-insights-into-pytorchs-fx-graphs">Probing the Depths: Surgical Insights into PyTorch’s FX Graphs</a></li>
        <li><a href="#stitching-together-efficiency-introducing-cuda-graphs">Stitching Together Efficiency: Introducing CUDA Graphs</a></li>
      </ul>
    </li>
    <li><a href="#into-the-operating-room-dissecting-the-mechanics-of-torch-compile">Into the Operating Room: Dissecting the Mechanics of Torch Compile</a>
      <ul>
        <li><a href="#operating-on-the-fly-torch-dynamos-jit-bytecode-transformation">Operating on the Fly: Torch Dynamo’s JIT Bytecode Transformation</a></li>
        <li><a href="#handling-dynamic-flow-with-surgical-precision-torch-dynamo-vs-static-tracing-tools">Handling Dynamic Flow with Surgical Precision: Torch Dynamo vs. Static Tracing Tools</a></li>
        <li><a href="#torch-inductor-the-final-scalpel-for-optimizing-computational-graphs">Torch Inductor: The Final Scalpel for Optimizing Computational Graphs</a>
          <ul>
            <li><a href="#key-optimization-techniques-with-torchinductor">Key Optimization Techniques with TorchInductor</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#scalpel-in-hand-a-practical-dive-into-torchcompile">Scalpel in Hand: A Practical Dive into torch.compile</a>
      <ul>
        <li>
          <ul>
            <li><a href="#intermediate-representation-ir">Intermediate Representation (IR)</a></li>
            <li><a href="#fx-graph-artifacts">FX Graph Artifacts</a></li>
          </ul>
        </li>
        <li><a href="#benchmarking-is-the-compiled-function-actually-faster">Benchmarking: Is the Compiled Function Actually Faster?</a>
          <ul>
            <li><a href="#gpu-poor-and-proud-tweaking-torchcompile-parameters-for-fun-and-slower-functions">GPU-Poor and Proud: Tweaking torch.compile Parameters for Fun (and Slower Functions)</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#conclusion-closing-the-incision-on-torchcompile">Conclusion: Closing the Incision on torch.compile</a></li>
  </ul>
</nav>
  </div>
</details>
<details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden">
  <summary
    class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#dissecting-torchcompile-a-surgeons-approach-to-pytorch-optimization">Dissecting torch.compile: A Surgeon’s Approach to PyTorch Optimization</a></li>
    <li><a href="#things-to-know-before-cutting-deep">Things to know before cutting deep</a>
      <ul>
        <li><a href="#slicing-through-the-layers-dissecting-pytorchs-computational-graphs">Slicing Through the Layers: Dissecting PyTorch’s Computational Graphs</a></li>
        <li><a href="#probing-the-depths-surgical-insights-into-pytorchs-fx-graphs">Probing the Depths: Surgical Insights into PyTorch’s FX Graphs</a></li>
        <li><a href="#stitching-together-efficiency-introducing-cuda-graphs">Stitching Together Efficiency: Introducing CUDA Graphs</a></li>
      </ul>
    </li>
    <li><a href="#into-the-operating-room-dissecting-the-mechanics-of-torch-compile">Into the Operating Room: Dissecting the Mechanics of Torch Compile</a>
      <ul>
        <li><a href="#operating-on-the-fly-torch-dynamos-jit-bytecode-transformation">Operating on the Fly: Torch Dynamo’s JIT Bytecode Transformation</a></li>
        <li><a href="#handling-dynamic-flow-with-surgical-precision-torch-dynamo-vs-static-tracing-tools">Handling Dynamic Flow with Surgical Precision: Torch Dynamo vs. Static Tracing Tools</a></li>
        <li><a href="#torch-inductor-the-final-scalpel-for-optimizing-computational-graphs">Torch Inductor: The Final Scalpel for Optimizing Computational Graphs</a>
          <ul>
            <li><a href="#key-optimization-techniques-with-torchinductor">Key Optimization Techniques with TorchInductor</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#scalpel-in-hand-a-practical-dive-into-torchcompile">Scalpel in Hand: A Practical Dive into torch.compile</a>
      <ul>
        <li>
          <ul>
            <li><a href="#intermediate-representation-ir">Intermediate Representation (IR)</a></li>
            <li><a href="#fx-graph-artifacts">FX Graph Artifacts</a></li>
          </ul>
        </li>
        <li><a href="#benchmarking-is-the-compiled-function-actually-faster">Benchmarking: Is the Compiled Function Actually Faster?</a>
          <ul>
            <li><a href="#gpu-poor-and-proud-tweaking-torchcompile-parameters-for-fun-and-slower-functions">GPU-Poor and Proud: Tweaking torch.compile Parameters for Fun (and Slower Functions)</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#conclusion-closing-the-incision-on-torchcompile">Conclusion: Closing the Incision on torch.compile</a></li>
  </ul>
</nav>
  </div>
</details>

<script>

  var margin = 200;
  var marginError = 50;

  (function () {
    var $window = $(window);
    var $toc = $('#TOCView');
    var tocHeight = $toc.height();

    function onResize() {
      var windowAndMarginHeight = $window.height() - margin;
      if(tocHeight >= windowAndMarginHeight) {
        $toc.css("overflow-y", "scroll")
        $toc.css("max-height", (windowAndMarginHeight + marginError) + "px")
      } else {
        $toc.css("overflow-y", "hidden")
        $toc.css("max-height", "9999999px")
      }
    }

    $window.on('resize', onResize);
    $(document).ready(onResize);
  })();



  (function () {
    var $toc = $('#TableOfContents');
    if ($toc.length > 0) {
      var $window = $(window);

      function onScroll() {
        var currentScroll = $window.scrollTop();
        var h = $('.anchor');
        var id = "";
        h.each(function (i, e) {
          e = $(e);
          if (e.offset().top - $(window).height()/3 <= currentScroll) {
            id = decodeURIComponent(e.attr('id'));
          }
        });
        var active = $toc.find('a.active');      
        if (active.length == 1 && active.eq(0).attr('href') == '#' + id) return true;

        active.each(function (i, e) {
          
            $(e).removeClass('active');
          
        });
        $toc.find('a[href="#' + id + '"]').addClass('active')
        $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
          $(e).children('a').parents('ul').show();          
        });
      }

      $window.on('scroll', onScroll);
      $(document).ready(function () {
        
        onScroll();
      });
    }
  })();


</script>
   </div>
      </div>
      

      <div class="min-w-0 min-h-0 max-w-fit">
        
        


        <div class="article-content max-w-prose mb-20">
          <blockquote>
<p>You can take a look at the GitHub repository of this blogpost <a href="https://github.com/DWarez/torch_compile_blogpost" target="_blank"><strong>at this link</strong></a>   

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>

</p>
</blockquote>
<p>Remember when machine learning was done using <code>Caffe</code>? The ML Surgeon remembers that.
If you didn’t catch the reference, too bad for you!</p>
<p>In the last few days, I&rsquo;ve been reflecting on how much easier machine learning has become in recent years. Not only do we now have a larger and higher-quality plethora of tools and frameworks—ones we could only dream of a few years ago—but the fact that these frameworks are so user-friendly is mind-boggling!</p>
<p>This got me thinking: are practitioners truly aware of the extreme complexity behind modern machine learning tools? Probably not. That’s why today, I want to dissect <strong>Torch Compile</strong>.</p>
<p>This article will be quite complex and lengthy, so gear up. But first, sterilize your hands.</p>


<h2 class="relative group">Dissecting torch.compile: A Surgeon’s Approach to PyTorch Optimization 
    <div id="dissecting-torchcompile-a-surgeons-approach-to-pytorch-optimization" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#dissecting-torchcompile-a-surgeons-approach-to-pytorch-optimization" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>At the end of 2022, PyTorch 2.0 was released, bringing with it a host of improvements and new features. Among them, the standout addition was undoubtedly <strong>torch.compile</strong>, a method designed to speed up PyTorch code. Its usage is quite straightforward: pass either a <code>torch.nn.Module</code> or a function to the method, and you’ll get an optimized version of it. For example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">optimized_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></span></code></pre></div><p>The <code>optimized_model</code> will, hopefully, run faster than the originally instantiated model.
Later on, we’ll conduct some benchmarks to demonstrate these speedups. So far, so simple, right?</p>
<p>But what actually happens when we use <code>torch.compile</code>? How can a single line of code optimize a model and achieve up to 3x speedups compared to classic, eager-mode PyTorch?</p>
<p>To understand that, we’ll need to cut deeper—time to get some blood on our hands (or, ideally, gloves).</p>


<h2 class="relative group">Things to know before cutting deep 
    <div id="things-to-know-before-cutting-deep" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#things-to-know-before-cutting-deep" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>Before we dive into the complexities hidden within <code>torch.compile</code>, it’s essential to cover some foundational concepts. These basics are crucial for understanding the roles of the tools involved in the compilation pipeline. Trust me, the intricacies behind <code>torch.compile</code> are quite convoluted, and there’s a lot to grasp before you can see the full picture. So, please be patient and make sure you fully understand each step before proceeding to the next.</p>


<h3 class="relative group">Slicing Through the Layers: Dissecting PyTorch’s Computational Graphs 
    <div id="slicing-through-the-layers-dissecting-pytorchs-computational-graphs" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#slicing-through-the-layers-dissecting-pytorchs-computational-graphs" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>Have you ever wondered what really happens when you execute PyTorch code? If not, shame on you! Don’t take for granted the incredible features right at your fingertips!</p>
<p>Let’s start from the beginning. Suppose you have code like this pseudocode:</p>
<pre tabindex="0"><code>fn(x op y)
</code></pre><p>where, <code>x</code> and <code>y</code> are two tensors, <code>op</code> is an operation (like the product <code>*</code> or sum <code>+</code>), and <code>fn</code> is a function (like <code>log</code> or <code>sin</code>).</p>
<p>This syntax results in a <strong>computational graph</strong>, which represents the operations that will be performed on the tensors. Below is a simple sketch of the computational graph that would result from the code above:</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /posts/torch-compile/forward_computational_graph_hu5803387795843449264.png 330w,
        /posts/torch-compile/forward_computational_graph_hu10887185310434375830.png 660w,
        /posts/torch-compile/forward_computational_graph_hu15119736865244087205.png 1024w,
        /posts/torch-compile/forward_computational_graph_hu6204957211308731291.png 2x"
        src="/posts/torch-compile/forward_computational_graph_hu10887185310434375830.png"
        alt="Forward Computational Graph"
      />
      <figcaption>Is this crooked? I can&rsquo;t really tell.</figcaption>
    </figure>
</p>
<p>In Pytorch, the graph is built <strong>dynamically</strong> as operations are applied to tensors, which is often referred as <em>define-by-run</em>.</p>
<p>But wait! That&rsquo;s only the forward step! We can’t train our models with just that!
Luckily for us, Pytorch provides <a href="https://pytorch.org/docs/stable/autograd.html" target="_blank"><strong>autograd</strong></a>, a system responsible for automatic differentiation. It records operations on tensors to form an <strong>autograd graph</strong>.
Long story short, PyTorch automatically computes gradients for tensors. A computational graph for the backward pass looks something like this:</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /posts/torch-compile/backward_computational_graph_hu5545627818671210287.png 330w,
        /posts/torch-compile/backward_computational_graph_hu11920705000497722419.png 660w,
        /posts/torch-compile/backward_computational_graph_hu10500698299188109313.png 1024w,
        /posts/torch-compile/backward_computational_graph_hu17525524064913201236.png 2x"
        src="/posts/torch-compile/backward_computational_graph_hu11920705000497722419.png"
        alt="Backward Computational Graph"
      />
      <figcaption>It&rsquo;s definitely crooked</figcaption>
    </figure>
</p>
<blockquote>
<p>⚠️ Note: I forgot to add arrows from <code>op</code> and <code>Z</code> to the <code>Derivative Magic</code> block!</p>
</blockquote>
<p>Damn, I&rsquo;m good at drawing. Anyway, in case you missed your calculus classes, the notation 
\(\frac{\partial Z}{\partial X}\) and 
\(\frac{\partial Z}{\partial Y}\) stands for the partial derivative of <code>Z</code> with respect to <code>X</code> (or <code>Y</code>).</p>
<p>As you can see, there are a lot of graphs involved. So, guess what <code>torch.compile</code> does to these graphs? That’s right—it optimizes them to make the overall computation faster.</p>


<h3 class="relative group">Probing the Depths: Surgical Insights into PyTorch’s FX Graphs 
    <div id="probing-the-depths-surgical-insights-into-pytorchs-fx-graphs" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#probing-the-depths-surgical-insights-into-pytorchs-fx-graphs" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>Let’s dive deeper into the world of graphs. In the previous section, we explored the critical role of computational graphs. But how do we go about optimizing them? I’m not referring to techniques or methodologies—I&rsquo;m talking about the nuts and bolts of how we can technically modify and optimize PyTorch&rsquo;s computational graphs.</p>
<p>To do that, we need a specialized toolkit. Fortunately, PyTorch equips us with just what we need: the <a href="https://arxiv.org/abs/2112.08429" target="_blank"><strong>FX</strong></a> toolkit.</p>
<p>The FX toolkit allows to modify <code>torch.nn.Module</code>s by implementing a pipeline consisting of a <strong>symbolic tracer</strong>, an <strong>intermediate representation</strong> (IR) and a <strong>Python code generator</strong>. This makes FX a powerful Python-to-Python transformation toolkit.</p>
<p>The symbolic tracer constructs a <code>torch.fx.GraphModule</code> by recording the operations that occur when the <code>nn.Module</code> is fed with fake data, called <strong>proxies</strong>.</p>
<p>A <code>GraphModule</code> is essentially a <code>nn.Module</code> generated from a <code>torch.fx.Graph</code>, which serves as the core data structure for FX’s internal representation.</p>
<p>With just a few lines of code, we can observe how the symbolic tracer and intermediate representation function:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.fx</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">m</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">gm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</span></span></code></pre></div><p>This script outputs the following graph representation:</p>
<pre tabindex="0"><code>graph():
    %x : [num_users=2] = placeholder[target=x]
    %linear : [num_users=1] = call_module[target=linear](args = (%x,), kwargs = {})
    %add : [num_users=1] = call_function[target=operator.add](args = (%linear, %x), kwargs = {})
    %relu : [num_users=1] = call_method[target=relu](args = (%add,), kwargs = {})
    return relu
</code></pre><p>This output shows the graph’s intermediate representation, which is made up of <code>Node</code>s. Without going too deep into the details, you can see references to module calls (e.g. <code>linear</code>), function calls (e.g. <code>add</code>), and method calls (e.g. <code>relu</code>). Each node also specifies the <strong>args</strong> for the operation, which are other nodes within the graph.</p>
<p>Once we have this graph, we can modify it as needed. Afterward, the <strong>code generator</strong> component takes over, creating a new <code>GraphModule</code> from the modified <code>Graph</code> data structure. I won’t dive into the specific techniques for modifying a graph here—this article is already long enough!</p>


<h3 class="relative group">Stitching Together Efficiency: Introducing CUDA Graphs 
    <div id="stitching-together-efficiency-introducing-cuda-graphs" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#stitching-together-efficiency-introducing-cuda-graphs" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>While we&rsquo;re on the subject of graphs, it’s worth highlighting another important feature: <strong>CUDA Graphs</strong>. Introduced in 2021, CUDA Graphs are a relatively new addition to the PyTorch ecosystem, specifically available for NVIDIA GPUs with CUDA version 10 or higher.</p>
<p>Typically, when operations are executed on the GPU, each kernel launch must be initiated from the CPU—a process that introduces noticeable overhead, especially when dealing with thousands of operations. Each individual launch might be small, but when accumulated, this overhead can impact performance.</p>
<p>CUDA Graphs address this by representing GPU operations as a single, cohesive graph. While building and launching this graph may initially be slower, the advantage lies in the fact that all subsequent operations remain on the GPU, significantly reducing the overhead caused by CPU-GPU communication.</p>
<p>The image below illustrates this concept perfectly:</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /posts/torch-compile/cuda_graph_hu1130890584496980636.png 330w,
        /posts/torch-compile/cuda_graph_hu13736437457921566354.png 660w,
        /posts/torch-compile/cuda_graph_hu17365644072580404427.png 1024w,
        /posts/torch-compile/cuda_graph_hu13967117992900421792.png 2x"
        src="/posts/torch-compile/cuda_graph_hu13736437457921566354.png"
        alt=""
      />
      <figcaption><a href="https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/" target="_blank">Credits to <strong>this blogpost</strong></a></figcaption>
    </figure>
</p>


<h2 class="relative group">Into the Operating Room: Dissecting the Mechanics of Torch Compile 
    <div id="into-the-operating-room-dissecting-the-mechanics-of-torch-compile" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#into-the-operating-room-dissecting-the-mechanics-of-torch-compile" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>After all this talk about graphs, it&rsquo;s finally time to get down to business. Now, we’re ready to make the incision and dive deep into <code>torch.compile</code> to explore its inner workings. Armed with the knowledge we’ve gained in the previous sections, this should feel like a well-prepared field trip into the body of PyTorch, right? I certainly hope so—my head’s already spinning from the sheer complexity of it all!</p>


<h3 class="relative group">Operating on the Fly: Torch Dynamo’s JIT Bytecode Transformation 
    <div id="operating-on-the-fly-torch-dynamos-jit-bytecode-transformation" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#operating-on-the-fly-torch-dynamos-jit-bytecode-transformation" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>Let&rsquo;s start with a definition: <strong>Torch Dynamo</strong> is a Python JIT compiler that uses CPython&rsquo;s frame evaluation API to dynamically modify the bytecode generated from Pytorch source.
That sentence might sound a bit overwhelming, so let’s take it step by step.</p>
<p>First, what is <strong>Just-in-time</strong> (JIT) compilation? It’s a compilation process that occurs during the execution of a program, rather than before (as with languages like C). In Python, this means that while the program is running, its bytecode is translated into machine code, which the system then executes. Here’s a simple diagram to illustrate:</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /posts/torch-compile/python_schema_hu892059387794601592.png 330w,
        /posts/torch-compile/python_schema_hu6874950270713104524.png 660w,
        /posts/torch-compile/python_schema_hu7958899415084392755.png 1024w,
        /posts/torch-compile/python_schema_hu3496970889048702844.png 2x"
        src="/posts/torch-compile/python_schema_hu6874950270713104524.png"
        alt=""
      />
      
    </figure>
</p>
<p>As you can see, the original Python source code is parsed into bytecode, which is easier to manage during execution. Now, thanks to the <strong>frame evaluation API</strong>, we can insert a middleware between the bytecode and the interpreter, as shown in the diagram below:</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /posts/torch-compile/frame_evaluation_hu15797033654603190872.png 330w,
        /posts/torch-compile/frame_evaluation_hu10777199593306000427.png 660w,
        /posts/torch-compile/frame_evaluation_hu1948742451148945910.png 1024w,
        /posts/torch-compile/frame_evaluation_hu8760490793802124212.png 2x"
        src="/posts/torch-compile/frame_evaluation_hu10777199593306000427.png"
        alt=""
      />
      
    </figure>
</p>
<p>This is where <strong>Torch Dynamo</strong> comes in. It acts as a middleware, intercepting the bytecode to rewrite it and extract FX graphs from the PyTorch operations defined in the source code.</p>
<p>Since Dynamo operates just-in-time, it dynamically intercepts bytecode during execution and extracts graphs based on the current state of the code. This allows us to work with dynamic graphs, adapting to the changing flow of execution. However, for the sake of performance, we want to avoid re-capturing graphs every time the same code runs—doing so repeatedly, as seen in frameworks like JAX, would result in unnecessary overhead.</p>
<p>To address this, Dynamo uses <strong>guards</strong>. These guards are conditions that check whether the graph needs to be re-captured. If nothing significant has changed since the last run, Dynamo will use the previously captured graph, avoiding the need to reconstruct it from scratch.</p>
<p>Here’s a code snippet to illustrate how guards work:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">_dynamo</span> <span class="k">as</span> <span class="n">torchdynamo</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">custom_compiler</span><span class="p">(</span><span class="n">graph_module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span> <span class="n">dummy_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">graph_module</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">print_tabular</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">graph_module</span><span class="o">.</span><span class="n">forward</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@torchdynamo.optimize</span><span class="p">(</span><span class="n">custom_compiler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">example</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">b</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">example</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</span></span></code></pre></div><p>To observe Dynamo in action, run the script with the following command to enable the appropriate logging level:</p>
<pre tabindex="0"><code>TORCH_LOGS=guards uv run src/dynamo.py
</code></pre><p>Here’s a snippet of the output:</p>
<pre tabindex="0"><code>[__guards] | +- GuardManager: source=L[&#39;a&#39;], accessed_by=DictGetItemGuardAccessor(a)
[__guards] | | +- TENSOR_MATCH: check_tensor(L[&#39;a&#39;], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[10], stride=[1])  # x = a / (torch.abs(a) + 1)  # src/dynamo.py:14 in example
</code></pre><p>As you can see, the output shows guards being used. These are essentially assertions that determine whether the graph should be reused or re-captured. For example, the <code>check_tensor</code> guard verifies properties of the <code>torch.Tensor</code>, such as <code>dtype</code>, <code>device</code>, <code>requires_grad</code>, and <code>size</code>. If any of these properties change, the guard triggers a re-capture of the graph, ensuring that it remains accurate for the current execution.</p>


<h3 class="relative group">Handling Dynamic Flow with Surgical Precision: Torch Dynamo vs. Static Tracing Tools 
    <div id="handling-dynamic-flow-with-surgical-precision-torch-dynamo-vs-static-tracing-tools" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#handling-dynamic-flow-with-surgical-precision-torch-dynamo-vs-static-tracing-tools" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>One of the standout features of Torch Dynamo, compared to other tracing tools like TorchScript or FX tracing, is its ability to trace dynamic graphs that involve data-dependent control flow. In simpler terms, this means that the execution path of the code depends on a dynamic value, which makes it impossible to capture within a static graph.</p>
<p>Here’s a simple example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">y</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="o">-</span><span class="n">y</span>
</span></span></code></pre></div><p>In this case, the returned value depends on the sum of the tensor <code>x</code>. Because of this dynamic condition, the function can’t be traced by a tool that only works with static graphs.</p>
<p>If we attempt to trace this function using TorchScript, it will fail silently, producing a static graph. This means that even if the condition <code>x.sum() &gt; 0</code> is false, the traced function will still return <code>y</code>, which is incorrect.</p>
<p>With <strong>FX tracing</strong>, however, we would get an exception like:</p>
<blockquote>
<p><code>raise TraceError('symbolically traced variables cannot be used as inputs to control flow') torch.fx.proxy.TraceError: symbolically traced variables cannot be used as inputs to control flow</code></p>
</blockquote>
<p>Trying to bypass this by providing concrete input arguments won’t work either, as FX tracing will still generate a static graph—leading to the same issues as TorchScript.</p>
<p>Although TorchScript can technically support data-dependent control flow, this requires significant changes to the codebase. Torch Dynamo, on the other hand, handles data-dependent control flow seamlessly, with no need for code modifications. When Dynamo encounters unsupported Python code (like control flow dependent on dynamic data), it breaks the computation graph, allows Python’s interpreter to process the unsupported code, and then resumes graph capture.</p>
<p>This feature also allows Dynamo to trace and optimize non-PyTorch code—another major limitation of both TorchScript and FX tracing.</p>


<h3 class="relative group">Torch Inductor: The Final Scalpel for Optimizing Computational Graphs 
    <div id="torch-inductor-the-final-scalpel-for-optimizing-computational-graphs" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#torch-inductor-the-final-scalpel-for-optimizing-computational-graphs" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>The last crucial tool in our arsenal is a compiler that knows how to transform the computational graph into highly efficient machine code. In this realm, this is typically called <strong>deep learning compiler</strong>. This is where <strong>TorchInductor</strong> comes in.</p>
<p>TorchInductor acts as the key performance engine for PyTorch’s deep learning models by compiling and optimizing the graph for both inference and training modes—something that many traditional backends struggle with. Most alternative backends are limited to <strong>inference-only</strong> optimizations, leaving a significant gap in performance during the training phase. TorchInductor fills this gap by targeting both modes of operation, offering a unified solution that performs well across different stages of machine learning pipelines.</p>
<p>TorchInductor supports both CPU and GPU architectures, adapting its optimizations based on the target hardware:</p>
<ul>
<li>
<p>For CPUs, TorchInductor generates highly efficient C++/<a href="https://www.openmp.org/" target="_blank"><strong>OpenMP</strong></a> code. OpenMP is a popular framework for parallel computing on CPUs, making it ideal for distributing workloads across multiple cores in modern processors. By leveraging OpenMP, Inductor ensures that the compiled code scales with CPU architectures for tasks like training and inference.</p>
</li>
<li>
<p>For GPUs, the generated code is written in <a href="https://openai.com/index/triton/" target="_blank"><strong>Triton</strong></a>, a high-level programming language designed for ease of use and speed, serving as a flexible alternative to CUDA. Triton is designed to simplify GPU programming by providing Python-like syntax, making it accessible to a broader range of developers. It supports NVIDIA GPUs with compute capability 7.0 or greater, as well as AMD GPUs with ROCm 5.2 or later. Though Triton’s support for CPUs is still evolving, its GPU capabilities make it a powerful ally in the quest for optimization.</p>
</li>
</ul>


<h4 class="relative group">Key Optimization Techniques with TorchInductor 
    <div id="key-optimization-techniques-with-torchinductor" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#key-optimization-techniques-with-torchinductor" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>Once the computational graph is fed into TorchInductor, a number of advanced optimization techniques are applied to significantly speed up the execution of your machine learning models.</p>
<ul>
<li>
<p><strong>Operation Fusion</strong></p>
<p>One of the primary optimizations that TorchInductor performs is operation fusion. This technique merges multiple operations into a single kernel, reducing the overhead associated with launching separate kernels and minimizing memory bandwidth usage. By combining operations, the system executes more tasks with fewer memory transactions, leading to noticeable performance boosts. This is particularly effective for GPU optimization, where kernel launch overhead can become a bottleneck.</p>
</li>
<li>
<p><strong>Memory Layout Transformations</strong></p>
<p>Another key technique involves memory layout transformations. The layout of tensors in memory can have a substantial impact on performance, especially when accessing data in parallel. TorchInductor reorders tensors to match the access patterns of the target hardware, ensuring that memory accesses are efficient. This process helps reduce cache misses, improve memory locality, and maximize the performance of both CPU and GPU systems.</p>
</li>
<li>
<p><strong>Loop Unrolling</strong></p>
<p>For CPU-bound operations, loop unrolling is a critical optimization. It involves transforming loops to execute multiple iterations in one go, reducing the overhead associated with loop control and improving cache utilization. By expanding loops, TorchInductor increases the efficiency of the CPU&rsquo;s instruction pipeline, making it better suited to handle parallel workloads and improving overall throughput.</p>
</li>
<li>
<p><strong>Parallelism and Hardware Utilization</strong></p>
<p>TorchInductor doesn&rsquo;t just focus on memory and execution optimizations—it also maximizes hardware utilization through enhanced parallelism. For GPUs, this means leveraging more cores simultaneously, while for CPUs, this means distributing tasks efficiently across multiple cores. The overall effect is that models run faster and scale better across different hardware setups.</p>
</li>
</ul>


<h2 class="relative group">Scalpel in Hand: A Practical Dive into torch.compile 
    <div id="scalpel-in-hand-a-practical-dive-into-torchcompile" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#scalpel-in-hand-a-practical-dive-into-torchcompile" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>Enough theory—let’s get our hands dirty! As any good surgeon knows, the best way to master a technique is through practice. In this section, we’ll explore the magic of <code>torch.compile</code> by dissecting its output and performance. We’ll first analyze what happens under the hood when we use <code>torch.compile</code>, and then we’ll run a benchmark to determine if the compiled function is truly faster.</p>
<p>Let’s start with a straightforward PyTorch function to keep things simple. This will allow us to focus on understanding how the compilation process works without being overwhelmed by complexity:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">simple_fn</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></div><p>Why this function?</p>
<ol>
<li><strong>Readability</strong>: It’s easier to understand and debug the logs with a minimal example compared to a full <code>nn.Module</code>.</li>
<li><strong>Interesting Output</strong>: This function performs a matrix multiplication (<code>matmul</code>) followed by a softmax operation. These are common operations in deep learning, and their transformation during compilation will give us insights into PyTorch’s lower-level optimizations.</li>
</ol>
<p>Now, let’s compile the function using <code>torch.compile</code> with the TorchInductor backend, and then run it with some random input tensors:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Create input tensors</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Compile the function using torch.compile() with TorchInductor backend</span>
</span></span><span class="line"><span class="cl"><span class="n">compiled_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">simple_fn</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;inductor&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Call the compiled function</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="n">compiled_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span></code></pre></div><p>If we run this script with debugging enabled (<code>TORCH_COMPILE_DEBUG=1</code>), a folder named <code>torch_compile_debug</code> will appear in the directory where the script was executed. This folder contains artifacts from the compilation process, such as:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">fx_graph_readable.py
</span></span><span class="line"><span class="cl">fx_graph_runnable.py
</span></span><span class="line"><span class="cl">fx_graph_transformed.py
</span></span><span class="line"><span class="cl">ir_post_fusion.txt
</span></span><span class="line"><span class="cl">ir_pre_fusion.txt
</span></span><span class="line"><span class="cl">output_code.py
</span></span></code></pre></div><p>Let’s break down the most interesting files:</p>


<h4 class="relative group">Intermediate Representation (IR) 
    <div id="intermediate-representation-ir" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#intermediate-representation-ir" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>The <strong>Intermediate Representation</strong> (IR) files provide snapshots of the computational graph before and after fusion. These files contain a low-level, abstracted view of the operations PyTorch will perform, allowing for optimizations to be applied.</p>
<ol>
<li><strong>Pre-Fusion IR</strong>: Shows the state of the computational graph before any optimizations have been applied.</li>
<li><strong>Post-Fusion IR</strong>: Displays the graph after key optimizations, such as <strong>operation fusion</strong>, have been performed.</li>
</ol>


<h4 class="relative group">FX Graph Artifacts 
    <div id="fx-graph-artifacts" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#fx-graph-artifacts" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>The <strong>FX graph</strong> files offer another layer of insight into the internal workings of <code>torch.compile</code>. Let’s open <code>fx_graph_readable.py</code> to examine how PyTorch translates the original function into an intermediate, traceable format:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="err">&lt;</span><span class="nc">lambda</span><span class="o">&gt;</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg0_1</span><span class="p">:</span> <span class="s2">&#34;f32[100, 100]&#34;</span><span class="p">,</span> <span class="n">arg1_1</span><span class="p">:</span> <span class="s2">&#34;f32[100, 100]&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># File: /home/dwarez/Documents/workspace/torch_compile/inductor.py:6 in simple_fn, code: z = torch.matmul(x, y)</span>
</span></span><span class="line"><span class="cl">      <span class="n">mm</span><span class="p">:</span> <span class="s2">&#34;f32[100, 100]&#34;</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">mm</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">arg1_1</span><span class="p">,</span> <span class="n">arg0_1</span><span class="p">);</span>  <span class="n">arg1_1</span> <span class="o">=</span> <span class="n">arg0_1</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1"># File: /home/dwarez/Documents/workspace/torch_compile/inductor.py:7 in simple_fn, code: return torch.nn.functional.softmax(z, dim=1)</span>
</span></span><span class="line"><span class="cl">      <span class="n">amax</span><span class="p">:</span> <span class="s2">&#34;f32[100, 1]&#34;</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">amax</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">sub</span><span class="p">:</span> <span class="s2">&#34;f32[100, 100]&#34;</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">sub</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">amax</span><span class="p">);</span>  <span class="n">mm</span> <span class="o">=</span> <span class="n">amax</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">      <span class="n">exp</span><span class="p">:</span> <span class="s2">&#34;f32[100, 100]&#34;</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">exp</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">sub</span><span class="p">);</span>  <span class="n">sub</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">      <span class="n">sum_1</span><span class="p">:</span> <span class="s2">&#34;f32[100, 1]&#34;</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">dim_IntList</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">div</span><span class="p">:</span> <span class="s2">&#34;f32[100, 100]&#34;</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">div</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">sum_1</span><span class="p">);</span>  <span class="n">exp</span> <span class="o">=</span> <span class="n">sum_1</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="p">(</span><span class="n">div</span><span class="p">,)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Here:</p>
<ul>
<li>The graph is structured as a PyTorch <code>nn.Module</code> with a <code>forward</code> method.</li>
<li>Each operation (such as <code>matmul</code> and <code>softmax</code>) is translated into lower-level <strong>ATen</strong> operations (<code>torch.ops.aten</code>), which represent the core tensor computations that PyTorch relies on.</li>
</ul>
<p>The code clearly shows how PyTorch’s softmax function has been decomposed into its mathematical components:</p>
<ol>
<li><strong>amax</strong>: Maximum value extraction across the specified dimension.</li>
<li><strong>sub</strong>: Subtraction of the maximum value from each element in the matrix.</li>
<li><strong>exp</strong>: Exponentiation of the result.</li>
<li><strong>sum</strong>: Summation across the same dimension.</li>
<li><strong>div</strong>: Division to normalize the output, resulting in the final <code>softmax</code>.</li>
</ol>
<p>This low-level breakdown reveals the granular steps involved in even simple operations, showing how TorchInductor prepares the graph for optimization.</p>
<p>When you see <code>torch.ops.aten</code>, it refers to <strong>ATen</strong>, the backend engine that powers PyTorch’s tensor computations. ATen is responsible for handling fundamental operations like matrix multiplication, element-wise functions, and reductions, ensuring that these operations are executed efficiently on both CPU and GPU.</p>
<p>Let’s dive into the contents of <code>fx_graph_runnable.py</code>, which provides another view of the computational graph. This file is generated as part of the artifact collection during the compilation process, and it’s crucial for understanding how PyTorch turns your high-level code into something that can actually run on your hardware.</p>
<p>Here’s what the file looks like:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">device</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.fx</span> <span class="k">as</span> <span class="nn">fx</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch._dynamo.testing</span> <span class="kn">import</span> <span class="n">rand_strided</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">inf</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch._inductor.inductor_prims</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch._dynamo.config</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch._inductor.config</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch._functorch.config</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.fx.experimental._config</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">debug_partitioner</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">unlift_effect_tokens</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">isolate_fails_code_str</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># torch version: 2.4.1+cu121</span>
</span></span><span class="line"><span class="cl"><span class="c1"># torch cuda version: 12.1</span>
</span></span><span class="line"><span class="cl"><span class="c1"># torch git version: 38b96d3399a695e704ed39b60dac733c3fbf20e2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># CUDA Info:</span>
</span></span><span class="line"><span class="cl"><span class="c1"># nvcc: NVIDIA (R) Cuda compiler driver</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Copyright (c) 2005-2024 NVIDIA Corporation</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Built on Wed_Aug_14_10:10:22_PDT_2024</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Cuda compilation tools, release 12.6, V12.6.68</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Build cuda_12.6.r12.6/compiler.34714021_0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># GPU Hardware Info:</span>
</span></span><span class="line"><span class="cl"><span class="c1"># NVIDIA GeForce RTX 4060 : 1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="o">*</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Repro</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg0_1</span><span class="p">,</span> <span class="n">arg1_1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">mm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">mm</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">arg1_1</span><span class="p">,</span> <span class="n">arg0_1</span><span class="p">);</span>  <span class="n">arg1_1</span> <span class="o">=</span> <span class="n">arg0_1</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="n">amax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">amax</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">sub</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">sub</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">amax</span><span class="p">);</span>  <span class="n">mm</span> <span class="o">=</span> <span class="n">amax</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="n">exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">exp</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">sub</span><span class="p">);</span>  <span class="n">sub</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="n">sum_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">dim_IntList</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">div</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">div</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">sum_1</span><span class="p">);</span>  <span class="n">exp</span> <span class="o">=</span> <span class="n">sum_1</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">(</span><span class="n">div</span><span class="p">,)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">load_args</span><span class="p">(</span><span class="n">reader</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">buf0</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">storage</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">40000</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">reader</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">buf0</span><span class="p">,</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">is_leaf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># arg0_1</span>
</span></span><span class="line"><span class="cl">    <span class="n">buf1</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">storage</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">40000</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">reader</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">buf1</span><span class="p">,</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">is_leaf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># arg1_1</span>
</span></span><span class="line"><span class="cl"><span class="n">load_args</span><span class="o">.</span><span class="n">_version</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">mod</span> <span class="o">=</span> <span class="n">Repro</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">torch._dynamo.repro.after_aot</span> <span class="kn">import</span> <span class="n">run_repro</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">run_repro</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">load_args</span><span class="p">,</span> <span class="n">accuracy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">command</span><span class="o">=</span><span class="s1">&#39;run&#39;</span><span class="p">,</span> <span class="n">save_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tracing_mode</span><span class="o">=</span><span class="s1">&#39;real&#39;</span><span class="p">,</span> <span class="n">check_str</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># To run it separately, do</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># mod, args = run_repro(mod, load_args, accuracy=False, command=&#39;get_args&#39;, save_dir=None, tracing_mode=&#39;real&#39;, check_str=None)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># mod(*args)</span>
</span></span></code></pre></div><p>By now you should be understaing this quite easily. Additionally to the <code>Repro</code> class (which is simply a runnable <code>nn.Module</code> of the computational graph), there&rsquo;s an <strong>argument loader function</strong>, called <code>load_args</code> and some useful <strong>debugging information</strong> in the comments, like CUDA version and underlying hardware.</p>
<p>Now, let’s take a look at the output code file (<code>output_code.py</code>), which contains the actual machine code generated by TorchInductor. Although the file is quite long, here’s a snippet that highlights a key portion:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cpp_fused__softmax_0</span> <span class="o">=</span> <span class="n">async_compile</span><span class="o">.</span><span class="n">cpp_pybinding</span><span class="p">([</span><span class="s1">&#39;const float*&#39;</span><span class="p">,</span> <span class="s1">&#39;float*&#39;</span><span class="p">,</span> <span class="s1">&#39;float*&#39;</span><span class="p">,</span> <span class="s1">&#39;float*&#39;</span><span class="p">,</span> <span class="s1">&#39;float*&#39;</span><span class="p">],</span> <span class="s1">&#39;&#39;&#39;
</span></span></span><span class="line"><span class="cl"><span class="s1">#include &#34;/tmp/torchinductor_dwarez/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&#34;
</span></span></span><span class="line"><span class="cl"><span class="s1">extern &#34;C&#34; void kernel(const float* in_ptr0,
</span></span></span><span class="line"><span class="cl"><span class="s1">...
</span></span></span></code></pre></div><p>What’s Happening Here?</p>
<ul>
<li>
<p><strong>C++ to Python Binding</strong>: This snippet shows the generation of a C++ binding for the <strong>fused softmax operation</strong>. Here, PyTorch has automatically compiled the <code>softmax</code> function into efficient C++ code, and this function will be called directly during execution.</p>
</li>
<li>
<p><strong>Asynchronous Compilation</strong>: The <code>async_compile.cpp_pybinding</code> function allows this C++ kernel to be invoked asynchronously from Python, ensuring that the CPU or GPU isn’t sitting idle waiting for Python’s GIL (Global Interpreter Lock).</p>
</li>
<li>
<p><strong>Fused Operations</strong>: Notice that the <code>softmax</code> operation has been fused into a single C++ function. Operation fusion is one of the key optimizations that TorchInductor applies to improve performance by reducing memory bandwidth and kernel launch overhead.</p>
</li>
</ul>


<h3 class="relative group">Benchmarking: Is the Compiled Function Actually Faster? 
    <div id="benchmarking-is-the-compiled-function-actually-faster" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#benchmarking-is-the-compiled-function-actually-faster" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>Let&rsquo;s put theory into practice and check if the compiled function outperforms the eager-mode function. We’ll use PyTorch&rsquo;s <code>torch.cuda</code> utilities to measure the execution time of both. Here’s the code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">N_ITERS</span> <span class="o">=</span> <span class="mi">10</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">timed</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">start</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">end</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">start</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">result</span> <span class="o">=</span> <span class="n">fn</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">end</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">elapsed_time</span><span class="p">(</span><span class="n">end</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define a simple function</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">simple_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">generate_data</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Compile the function using torch.compile() with TorchInductor backend</span>
</span></span><span class="line"><span class="cl"><span class="n">compiled_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">simple_fn</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;inductor&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">eager_times</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_ITERS</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">inp</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">eager_time</span> <span class="o">=</span> <span class="n">timed</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">simple_fn</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inp</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">    <span class="n">eager_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eager_time</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;eager eval time </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">eager_time</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;~&#34;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">compile_times</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_ITERS</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">inp</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">compile_time</span> <span class="o">=</span> <span class="n">timed</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">compiled_fn</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inp</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">    <span class="n">compile_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">compile_time</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;compile eval time </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">compile_time</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;~&#34;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">eager_med</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">eager_times</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">compile_med</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">compile_times</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">speedup</span> <span class="o">=</span> <span class="n">eager_med</span> <span class="o">/</span> <span class="n">compile_med</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="sa">f</span><span class="s2">&#34;(eval) eager median: </span><span class="si">{</span><span class="n">eager_med</span><span class="si">}</span><span class="s2">, compile median: </span><span class="si">{</span><span class="n">compile_med</span><span class="si">}</span><span class="s2">, speedup: </span><span class="si">{</span><span class="n">speedup</span><span class="si">}</span><span class="s2">x&#34;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;~&#34;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span></span></code></pre></div><p>When running this script, you might see an output like this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 0: 0.018083839416503905
</span></span><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 1: 6.585600227117538e-05
</span></span><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 2: 2.332800067961216e-05
</span></span><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 3: 1.8239999189972877e-05
</span></span><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 4: 1.744000054895878e-05
</span></span><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 5: 1.6383999958634378e-05
</span></span><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 6: 1.6383999958634378e-05
</span></span><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 7: 1.711999997496605e-05
</span></span><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 8: 1.5231999568641186e-05
</span></span><span class="line"><span class="cl">eager <span class="nb">eval</span> <span class="nb">time</span> 9: 1.535999961197376e-05
</span></span><span class="line"><span class="cl">~~~~~~~~~~
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 0: 0.8755618286132812
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 1: 0.00010204800218343735
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 2: 5.8816000819206235e-05
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 3: 4.831999912858009e-05
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 4: 4.790399968624115e-05
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 5: 4.1280001401901244e-05
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 6: 3.82080003619194e-05
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 7: 3.683200106024742e-05
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 8: 3.686400130391121e-05
</span></span><span class="line"><span class="cl">compile <span class="nb">eval</span> <span class="nb">time</span> 9: 3.481600061058998e-05
</span></span><span class="line"><span class="cl">~~~~~~~~~~
</span></span><span class="line"><span class="cl"><span class="o">(</span><span class="nb">eval</span><span class="o">)</span> eager median: 1.7280000261962412e-05, compile median: 4.45920005440712e-05, speedup: 0.3875134564748722x
</span></span><span class="line"><span class="cl">~~~~~~~~~~
</span></span></code></pre></div><p>Surprisingly, the compiled function was slower than the eager-mode one, with a speedup less than 1 (0.39x). Let&rsquo;s break down why this happens:</p>
<ol>
<li>
<p><strong>Low Computational Complexity</strong>: The benchmarked function is too simple: it performs just a matrix multiplication followed by a softmax. These operations are lightweight, meaning they don’t provide enough work for the compilation optimizations to shine. The overhead introduced by the compilation process outweighs the benefits of the optimizations, resulting in slower execution.</p>
<p>In this case, there&rsquo;s no significant performance gain from calling a fused softmax function because there’s nothing substantial to fuse—just a basic matrix operation and activation function.</p>
</li>
<li>
<p><strong>Compilation Overhead</strong>: Notice that the first couple of iterations of the compiled function are <strong>much slower</strong> than the rest. This is due to the overhead introduced by the compilation step. The TorchInductor backend needs time to analyze and compile the computational graph into optimized code.
Once the graph is compiled, subsequent iterations are much faster because PyTorch uses the cached version of the graph, avoiding recompilation. So, if you run many iterations, the compilation time becomes less of a factor, and you’ll see the true performance gains.</p>
</li>
<li>
<p><strong>Eager Mode’s Instant Execution</strong>: Eager mode is designed to run PyTorch operations immediately without any ahead-of-time optimizations, which is ideal for small, one-off operations like this. While compiled execution becomes faster over time, eager mode benefits from its simplicity and immediacy for lightweight tasks.</p>
</li>
</ol>
<p>While this example shows a slowdown, that’s because the workload is too small to benefit from TorchInductor’s optimizations. Compiled execution shines when dealing with larger models or heavier workloads. For a more substantial example where the compiled function outperforms eager mode, check out <a href="https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html#demonstrating-speedups" target="_blank"><strong>this link</strong></a>.</p>


<h4 class="relative group">GPU-Poor and Proud: Tweaking torch.compile Parameters for Fun (and Slower Functions) 
    <div id="gpu-poor-and-proud-tweaking-torchcompile-parameters-for-fun-and-slower-functions" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#gpu-poor-and-proud-tweaking-torchcompile-parameters-for-fun-and-slower-functions" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>Let&rsquo;s try to tweak some <code>torch.compile</code> parameters and see what happens, shall we?</p>
<p>First up, let&rsquo;s play around with <strong>CUDA graphs</strong>. While CUDA graphs are great at reducing host-to-device communication overhead, that’s not exactly helpful when our function is so simple it might as well be considered an atomic operation. But hey, let&rsquo;s try it anyway!</p>
<p>We can try this backend by simply specifying it in <code>torch.compile</code>&rsquo;s arguments, like this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">compiled_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">simple_fn</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;cudagraphs&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>And here’s the &ldquo;amazing&rdquo; speedup result:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="o">(</span><span class="nb">eval</span><span class="o">)</span> eager median: 1.635199971497059e-05, compile median: 0.00019219200313091278, speedup: 0.08508158221251444x
</span></span></code></pre></div><p>Oh no! It&rsquo;s slower&hellip; again! Turns out wrapping a super-simple function in a CUDA graph is like putting racing tires on a tricycle—you’re not going anywhere faster.</p>
<p>Another thing that we could try is to change the <code>mode</code> parameter. This is a way of specifying what should be the focus of the compilation. The default mode is a good balance between performance and overhead, but there are other modalities like <code>reduce-overhead</code> which relies on CUDA graphs or <code>max-autotune</code>, which also relies on CUDA graphs and Triton based matrix multiplications and convolutions.</p>
<p>So naturally, let&rsquo;s crank it up to &ldquo;max&rdquo; with:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">compiled_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">simple_fn</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;inductor&#34;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;max-autotune&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>Drumroll, please&hellip; and the results:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="o">(</span><span class="nb">eval</span><span class="o">)</span> eager median: 1.5343999955803157e-05, compile median: 4.190399870276451e-05, speedup: 0.36617030428627984x
</span></span></code></pre></div><p>Once again, we&rsquo;ve hit a slowdown. But wait, what&rsquo;s this warning?</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">W0924 11:37:01.192000 <span class="m">123584511351680</span> torch/_inductor/utils.py:977<span class="o">]</span> <span class="o">[</span>0/0<span class="o">]</span> Not enough SMs to use max_autotune_gemm mode
</span></span></code></pre></div><p>Uh-oh. PyTorch is warning me that I don’t have enough <a href="https://dwarez.github.io/posts/cpu-gpu-architecture/#cerebral-cortex" target="_blank"><strong>SMs</strong></a>. Let’s check the code that triggered this passive-aggressive insult from PyTorch:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@functools.lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">is_big_gpu</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">min_sms</span> <span class="o">=</span> <span class="mi">68</span>  <span class="c1"># 3080</span>
</span></span><span class="line"><span class="cl">    <span class="n">avail_sms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">multi_processor_count</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">avail_sms</span> <span class="o">&lt;</span> <span class="n">min_sms</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;Not enough SMs to use max_autotune_gemm mode&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">extra</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;min_sms&#34;</span><span class="p">:</span> <span class="n">min_sms</span><span class="p">,</span> <span class="s2">&#34;avail_sms&#34;</span><span class="p">:</span> <span class="n">avail_sms</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="kc">True</span>
</span></span></code></pre></div><p>So, PyTorch basically looked at my hardware and said, &ldquo;Sorry, but you&rsquo;re too GPU-poor to hang with the big boys.&rdquo; Not cool, PyTorch, not cool at all.</p>
<p>And with that, I’m officially done with this article!</p>


<h2 class="relative group">Conclusion: Closing the Incision on torch.compile 
    <div id="conclusion-closing-the-incision-on-torchcompile" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#conclusion-closing-the-incision-on-torchcompile" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>After a deep surgical dive into the world of <code>torch.compile</code>, we&rsquo;ve explored key components like <strong>Torch Dynamo</strong>, <strong>Torch Inductor</strong>, <strong>CUDA graphs</strong>, and more—each acting like specialized tools in the operating room of PyTorch optimization. Dynamo handles the &ldquo;diagnosis,&rdquo; tracing and transforming eager-mode operations into a computational graph, while Inductor steps in like a skilled surgeon to optimize that graph and generate fast machine code for CPUs and GPUs. CUDA graphs reduce the back-and-forth between the host and the GPU, making the &ldquo;patient&rdquo; function more efficient by minimizing communication.</p>
<p>However, as our benchmarks revealed, not every function needs major surgery. Sometimes, a simple bandage is better than complex procedures. In fact, when we tried to optimize a lightweight function, the compilation overhead actually made it slower. And yes, it turns out being <strong>GPU-poor</strong> can hold you back, as our GPU didn&rsquo;t have the strength for <code>max-autotune</code>—PyTorch’s gentle reminder that sometimes, you just need a more powerful toolkit.</p>
<p>In the end, optimization is like surgery—use the right tool for the right task, and remember, not every patient needs to be on the table!</p>
<p>Now, if you’ll excuse me, I’m off to cry over my GPU specs. Bye!</p>

          
          
          
        </div>
        
        

        
        
  
  <section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://localhost:1313/posts/torch-compile/&amp;title=Dissecting%20torch.compile:%20Surgical%20Precision%20in%20PyTorch%20Optimization"
      title="Share on LinkedIn"
      aria-label="Share on LinkedIn"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://t.me/share/url?url=http://localhost:1313/posts/torch-compile/&amp;resubmit=true&amp;title=Dissecting%20torch.compile:%20Surgical%20Precision%20in%20PyTorch%20Optimization"
      title=""
      aria-label=""
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M248,8C111.033,8,0,119.033,0,256S111.033,504,248,504,496,392.967,496,256,384.967,8,248,8ZM362.952,176.66c-3.732,39.215-19.881,134.378-28.1,178.3-3.476,18.584-10.322,24.816-16.948,25.425-14.4,1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25,5.342-39.5,3.652-3.793,67.107-61.51,68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608,69.142-14.845,10.194-26.894,9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7,18.45-13.7,108.446-47.248,144.628-62.3c68.872-28.647,83.183-33.623,92.511-33.789,2.052-.034,6.639.474,9.61,2.885a10.452,10.452,0,0,1,3.53,6.716A43.765,43.765,0,0,1,362.952,176.66Z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://reddit.com/submit/?url=http://localhost:1313/posts/torch-compile/&amp;resubmit=true&amp;title=Dissecting%20torch.compile:%20Surgical%20Precision%20in%20PyTorch%20Optimization"
      title="Submit to Reddit"
      aria-label="Submit to Reddit"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="mailto:?body=http://localhost:1313/posts/torch-compile/&amp;subject=Dissecting%20torch.compile:%20Surgical%20Precision%20in%20PyTorch%20Optimization"
      title="Send via email"
      aria-label="Send via email"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>

  </span>


    </a>
      
    
  </section>


        


<h2 class="mt-8 text-2xl font-extrabold mb-10">Related</h2>
<section class="w-full grid gap-4 sm:grid-cols-2 md:grid-cols-3">
  
  

  <a href="/posts/ten-minutes-to-rag/" class="min-w-full">
    
    <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

      <div class="px-6 py-4">

        
        <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
          href="/posts/ten-minutes-to-rag/">A quick incision: ten minutes to RAG</div>
        

        <div class="text-sm text-neutral-500 dark:text-neutral-400">
          

















  













<div class="flex flex-row flex-wrap items-center">
  
  
  <span title="Reading time">8 mins</span>
  

  
  
</div>


<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
</div>




<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/rag/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Rag
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/llm/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Llm
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/vector-db/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Vector-Db
  </span>
</span>
  </span>
  
  
  
  
</div>




        </div>

        
      </div>
      <div class="px-6 pt-4 pb-2">

      </div>
    </div>
  </a>

  
  

  <a href="/posts/profiling-introduction/" class="min-w-full">
    
    <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

      <div class="px-6 py-4">

        
        <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
          href="/posts/profiling-introduction/">Performing Kernel Surgery: Profiling CUDA Kernels with NVIDIA Nsight Compute</div>
        

        <div class="text-sm text-neutral-500 dark:text-neutral-400">
          

















  













<div class="flex flex-row flex-wrap items-center">
  
  
  <span title="Reading time">9 mins</span>
  

  
  
</div>


<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
</div>




<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/cuda/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Cuda
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/profiling/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Profiling
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/optimization/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Optimization
  </span>
</span>
  </span>
  
  
  
  
</div>




        </div>

        
      </div>
      <div class="px-6 pt-4 pb-2">

      </div>
    </div>
  </a>

  
  

  <a href="/posts/matrix-multiplication/" class="min-w-full">
    
    <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

      <div class="px-6 py-4">

        
        <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
          href="/posts/matrix-multiplication/">A Machine Learning Surgeon’s Toolkit: Advanced Matrix Multiplication in CUDA</div>
        

        <div class="text-sm text-neutral-500 dark:text-neutral-400">
          

















  













<div class="flex flex-row flex-wrap items-center">
  
  
  <span title="Reading time">16 mins</span>
  

  
  
</div>


<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
</div>




<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/cuda/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Cuda
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/gpu/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Gpu
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/optimization/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Optimization
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/matrix-multiplication/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Matrix-Multiplication
  </span>
</span>
  </span>
  
  
  
  
</div>




        </div>

        
      </div>
      <div class="px-6 pt-4 pb-2">

      </div>
    </div>
  </a>

  
  

  <a href="/posts/cpu-gpu-architecture/" class="min-w-full">
    
    <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

      <div class="px-6 py-4">

        
        <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
          href="/posts/cpu-gpu-architecture/">Cerebral Cortex and Hippocampus: Understanding the Computational and Memory Design of GPUs</div>
        

        <div class="text-sm text-neutral-500 dark:text-neutral-400">
          

















  













<div class="flex flex-row flex-wrap items-center">
  
  
  <span title="Reading time">13 mins</span>
  

  
  
</div>


<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
</div>




<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/gpu/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Gpu
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/architecture/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Architecture
  </span>
</span>
  </span>
  
  
  
  
</div>




        </div>

        
      </div>
      <div class="px-6 pt-4 pb-2">

      </div>
    </div>
  </a>

  
  

  <a href="/posts/hello-cuda/" class="min-w-full">
    
    <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

      <div class="px-6 py-4">

        
        <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
          href="/posts/hello-cuda/">Hello CUDA: A Surgical Dissection</div>
        

        <div class="text-sm text-neutral-500 dark:text-neutral-400">
          

















  













<div class="flex flex-row flex-wrap items-center">
  
  
  <span title="Reading time">13 mins</span>
  

  
  
</div>


<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
</div>




<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/gpu-programming/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Gpu-Programming
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/cuda/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Cuda
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/basics/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Basics
  </span>
</span>
  </span>
  
  
  
  
</div>




        </div>

        
      </div>
      <div class="px-6 pt-4 pb-2">

      </div>
    </div>
  </a>

  
  

  <a href="/posts/pruning-intro/" class="min-w-full">
    
    <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

      <div class="px-6 py-4">

        
        <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
          href="/posts/pruning-intro/">An Introduction to Sparsity for Efficient Neural Network Inference</div>
        

        <div class="text-sm text-neutral-500 dark:text-neutral-400">
          

















  













<div class="flex flex-row flex-wrap items-center">
  
  
  <span title="Reading time">7 mins</span>
  

  
  
</div>


<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
</div>




<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/pruning/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Pruning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/optimization/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Optimization
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/inference/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Inference
  </span>
</span>
  </span>
  
  
  
  
</div>




        </div>

        
      </div>
      <div class="px-6 pt-4 pb-2">

      </div>
    </div>
  </a>

  
</section>

  
      </div>
     
      
      
        
        
          
          
        
      <script>
        var oid = "views_posts\/torch_compile\/index.md"
        var oid_likes = "likes_posts\/torch_compile\/index.md"
      </script>
      
      
      <script type="text/javascript" src="/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js" integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q&#43;oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script>
      
  
    </section>
  <footer class="pt-8 max-w-prose print:hidden">

    
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group mr-3" href="/posts/ten-minutes-to-rag/">
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >A quick incision: ten minutes to RAG</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
        </span>
      </div>
    </div>
  


    
  </footer>
</article>

      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top" title="Scroll to top">
    &uarr;
  </a>
</div>
    </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
    <nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400">
      <ul class="flex flex-col list-none sm:flex-row">
        
        <li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
          <a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href="/tags/"
            title="">
            
            Tags
          </a>
        </li>
        
        <li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
          <a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href="/authors/"
            title="">
            
            Authors
          </a>
        </li>
        
      </ul>
    </nav>
    
  
  <div class="flex items-center justify-between">

    
    
    <p class="text-sm text-neutral-500 dark:text-neutral-400">
      &copy;
      2024
      Dario Salvati
    </p>
    

    
    
    <p class="text-xs text-neutral-500 dark:text-neutral-400">
      
      
      Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://blowfish.page/" target="_blank" rel="noopener noreferrer">Blowfish</a>
    </p>
    

  </div>
  <script>
    
    mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
      margin: 24,
      background: 'rgba(0,0,0,0.5)',
      scrollOffset: 0,
    })
    
  </script>
  
  
  <script type="text/javascript" src="/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js" integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
  <a rel="me" href="https://masto.ai/@blowfish"></a>
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

</html>
