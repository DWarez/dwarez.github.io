<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Optimization on The ML Surgeon</title><link>https://dwarez.github.io/tags/optimization/</link><description>Recent content in Optimization on The ML Surgeon</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 Dario Salvati</copyright><lastBuildDate>Sun, 10 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://dwarez.github.io/tags/optimization/index.xml" rel="self" type="application/rss+xml"/><item><title>Quantization</title><link>https://dwarez.github.io/posts/quantization/</link><pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/quantization/</guid><description>&lt;p>As humans, we perceive space and time as a seamless, continuous flow. This perception leads us to believe that continuity—and perhaps even infinity—is a fundamental aspect of nature. However, some scientific theories challenge this assumption. For example, &lt;strong>string theory&lt;/strong> posits that the universe&amp;rsquo;s fundamental components are tiny, vibrating strings, where different vibrations define different particles. Similarly, &lt;strong>loop quantum gravity&lt;/strong> suggests that space itself is made up of discrete &amp;ldquo;grains,&amp;rdquo; implying that reality might not be as continuous as it appears.&lt;/p></description></item><item><title>Performing Kernel Surgery: Profiling CUDA Kernels with NVIDIA Nsight Compute</title><link>https://dwarez.github.io/posts/profiling-introduction/</link><pubDate>Mon, 15 Jul 2024 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/profiling-introduction/</guid><description>&lt;p>Being a Machine Learning Surgeon is not an easy life. We not only have to deal with intricate machine learning systems but also navigate the additional complexities surrounding them. To be a proficient ML Surgeon, we must develop a diverse skill set. First and foremost, we need a deep understanding of machine learning and deep learning. Additionally, we must be adept at writing software, building infrastructures to host and integrate models, managing large volumes of data, and much more. This requires familiarity with numerous tools.&lt;/p></description></item><item><title>A Machine Learning Surgeon’s Toolkit: Advanced Matrix Multiplication in CUDA</title><link>https://dwarez.github.io/posts/matrix-multiplication/</link><pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/matrix-multiplication/</guid><description>&lt;p>During the first year of my Master&amp;rsquo;s Degree in Computer Science, I had to complete a project for a Machine Learning course. It involved implementing a small feed-forward neural network framework from scratch, using only numerical libraries and coding elements such as loss functions, backpropagation, and the feed-forward step.&lt;/p></description></item><item><title>An Introduction to Sparsity for Efficient Neural Network Inference</title><link>https://dwarez.github.io/posts/pruning-intro/</link><pubDate>Sun, 05 May 2024 00:00:00 +0000</pubDate><guid>https://dwarez.github.io/posts/pruning-intro/</guid><description>&lt;blockquote>
&lt;p>&lt;strong>&lt;em>NOTE:&lt;/em>&lt;/strong> This post was written before the Machine Learning Surgeon got in charge of the blog, that&amp;rsquo;s why there are no references to surgical operations!&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Large Language Model&lt;/strong>. How many times did you read that term? Nowadays, the popularity of Artificial Intelligence is to be attributed to the exceptional results obtained, in the past few years, by applications that leverage large models. Surely, you know the most popular one, ChatGPT, made by OpenAI.&lt;/p></description></item></channel></rss>