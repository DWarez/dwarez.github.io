<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on The ML Surgeon</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on The ML Surgeon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© 2024 Dario Salvati</copyright>
    <lastBuildDate>Sun, 01 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Torch compile</title>
      <link>http://localhost:1313/posts/torch-compile/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/torch-compile/</guid>
      <description>&lt;p&gt;Remember when machine learning was done using Caffe? The ML Surgeon remembers that.
If you didn’t catch the reference, too bad for you!&lt;/p&gt;
&lt;p&gt;In the last few days, I&amp;rsquo;ve been reflecting on how much easier machine learning has become in recent years. Not only do we now have a larger and higher-quality plethora of tools and frameworks—ones we could only dream of a few years ago—but the fact that these frameworks are so user-friendly is mind-boggling!&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>A quick incision: ten minutes to RAG</title>
      <link>http://localhost:1313/posts/ten-minutes-to-rag/</link>
      <pubDate>Thu, 29 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/ten-minutes-to-rag/</guid>
      <description>&lt;p&gt;Hello, fellow surgeons! How is life treating you? I hope you&amp;rsquo;ve spent your vacation relaxing, far, far away from the tools of our trade. After all, a good surgeon needs to rest after a long year of work and learning, right? With that in mind, I&amp;rsquo;ve chosen a simple yet useful topic to discuss today, so you can stay relaxed and not worry about the tremendous complexity of our field—at least for now.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Performing Kernel Surgery: Profiling CUDA Kernels with NVIDIA Nsight Compute</title>
      <link>http://localhost:1313/posts/profiling-introduction/</link>
      <pubDate>Mon, 15 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/profiling-introduction/</guid>
      <description>&lt;p&gt;Being a Machine Learning Surgeon is not an easy life. We not only have to deal with intricate machine learning systems but also navigate the additional complexities surrounding them. To be a proficient ML Surgeon, we must develop a diverse skill set. First and foremost, we need a deep understanding of machine learning and deep learning. Additionally, we must be adept at writing software, building infrastructures to host and integrate models, managing large volumes of data, and much more. This requires familiarity with numerous tools.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>A Machine Learning Surgeon’s Toolkit: Advanced Matrix Multiplication in CUDA</title>
      <link>http://localhost:1313/posts/matrix-multiplication/</link>
      <pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/matrix-multiplication/</guid>
      <description>&lt;p&gt;During the first year of my Master&amp;rsquo;s Degree in Computer Science, I had to complete a project for a Machine Learning course. It involved implementing a small feed-forward neural network framework from scratch, using only numerical libraries and coding elements such as loss functions, backpropagation, and the feed-forward step.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Cerebral Cortex and Hippocampus: Understanding the Computational and Memory Design of GPUs</title>
      <link>http://localhost:1313/posts/cpu-gpu-architecture/</link>
      <pubDate>Fri, 14 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/cpu-gpu-architecture/</guid>
      <description>&lt;p&gt;Would you operate on a human body without knowing its organs? Similarly, how can you effectively write a GPU kernel without understanding the underlying hardware? This is why it&amp;rsquo;s crucial to understand how GPUs function. Knowing the philosophy behind their architectural design, the problems they aim to solve, and the reasons for their specific construction is essential for leveraging their full potential.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Hello CUDA: A Surgical Dissection</title>
      <link>http://localhost:1313/posts/hello-cuda/</link>
      <pubDate>Mon, 06 May 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/hello-cuda/</guid>
      <description>&lt;p&gt;In case you didn&amp;rsquo;t already know, &lt;a href=&#34;https://it.wikipedia.org/wiki/CUDA&#34;   target=&#34;_blank&#34;&gt;
    CUDA&lt;/a&gt; is a parallel computing platform and API, developed by NVIDIA, that enables programmers to exploit certain types of GPUs. Not too long ago (around until 2007), GPUs were solely utilized for graphics rendering, and programmers had to depend on very specific graphics APIs to utilize them for solving general problems.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>An Introduction to Sparsity for Efficient Neural Network Inference</title>
      <link>http://localhost:1313/posts/pruning-intro/</link>
      <pubDate>Sun, 05 May 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/pruning-intro/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;NOTE:&lt;/em&gt;&lt;/strong&gt;  This post was written before the Machine Learning Surgeon got in charge of the blog, that&amp;rsquo;s why there are no references to surgical operations!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Large Language Model&lt;/strong&gt;. How many times did you read that term? Nowadays, the popularity of Artificial Intelligence is to be attributed to the exceptional results obtained, in the past few years, by applications that leverage large models. Surely, you know the most popular one, ChatGPT, made by OpenAI.&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
